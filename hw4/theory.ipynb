{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теоретические задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Как выглядит бинарный линейный классификатор?\n",
    "\n",
    "Пусть $x_1, x_2, ..., x_n$ - признаки объектов. \n",
    "\n",
    "Ответ бинарного линейного классификатора задается формулой\n",
    "\n",
    "$a(x) = sign(w_0 + w_1 x_1 + ... + w_n x_n) = sign(w_0 + <w, x>)$, где веса w - параметры модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Отступ алгоритма на объекте\n",
    "Отступ алгоритма бинарой классификации на объекте x задается следующим образом:\n",
    "\n",
    "$M = y f(x)$\n",
    "\n",
    "Таким образом, отступ положителен, если класс объекта предсказан правильно и отрицателен, если неправильно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Приведение классификаторов к одному виду\n",
    "\n",
    "Для того, чтобы свести классификатор вида \n",
    "$a(x) = sign(<w, x> - w_0)$ к виду $a(x) = sign(<w, x>)$ \n",
    "достаточно добавить к вектору признаков каждого объекта фиктивный признак, всегда равный 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Функционал эмпирического риска.\n",
    "\n",
    "$Q(w) = \\sum L(M_i(x))$, где $L$ - функция потерь, $M_i$ - отступ алгоритма на i-м объекте\n",
    "\n",
    "Функционал эмпирического риска идеального алгоритма, который предсказывает все ответа правильно,  равен нулю"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\n",
    "\n",
    "Можно взять все веса модели равными нулю. Тогда $f(x) = <w, x> = 0$ для любого объекта $x$\n",
    "\n",
    "$M(x_i) = 0$ $\\forall x$\n",
    "\n",
    "Следовательно, пороговая функция потерь равна нулю для любого объекта и функционал эмпирического риска равен нулю, параметры $w$ оптимальны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.\n",
    "\n",
    "$Q(w) = \\sum L(M_i(x))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.\n",
    "\n",
    "Функция потерь характеризует величину отклонения ответа алгоритма на объекте от истинного значения целевого признака на этом объекте. Обычно функция потерь в задачах классификации является функцией от отступа. \n",
    "\n",
    "Если отступ отрицательный, то ответ алгоритма далек от истинного и функция потерь принимает большие значения.\n",
    "\n",
    "Если отступ положительный, логично не штрафовать модель за предсказание на объекте, функция потерь мала по значению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.\n",
    "\n",
    "В качестве примера негладкой функции потерь можно привести пороговую функцию потерь\n",
    "\n",
    "$L(y, y') = [y \\ne y']$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Регуляризация\n",
    "\n",
    "Для борьбы с переобучением используется прием регуляризации:  к функционалу ошибки добавлется штраф за высокие значения коэффициентов модели. В результате оптимизируемый функционал ограничивает сложность модели.\n",
    "\n",
    "Чаще всего используется L1 - регуляризатор и L2 - регуляризатор, которые задаются по формулам\n",
    "\n",
    "$\\sum |w_i| $ и $\\sum w_i^2$ соответственно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.\n",
    "\n",
    "Если алгоритм переобучен, то он обладает низкой обобщающей способностью, так как его ошибка на тестовой выборке сильно превышает его ошибку на обучающей выборке. \n",
    "\n",
    "Регуляризация позволяет бороться с переобучением, а значит, увеличивает обобщающую способность алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.\n",
    "\n",
    "Острые минимумы функционала эмпирического риска говорят о том, что функция риска сильно меняется даже при небольшом изменении признаков. Из этого можно сделать вывод, что веса модели велики по значению и присутствует явление переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.\n",
    "\n",
    "Регуляризация добавляет к функции аппроксимированного эмпирического риска штраф за переобучение модели. \n",
    "\n",
    "${\\overline{Q}(w)} = Q(w) + \\sum \\|w_i\\|^{\\alpha}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.\n",
    "\n",
    "На обучающей выборке большее значение функции аппроксимированного эмпирического риска будет иметь алгоритм с регуляризацией, так как без применения регуляризации можно получить сколь угодно низкую ошибку на обучающей выборке, переобучившись. Регуляризатор ограничивает сложность модели, добавляя штраф за высокие веса, следовательно, минимум оптимизируемого функционала с учетом регуляризации может не совпадать с глобальным минимумом самого функционала аппроксимированного эмпирического риска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.\n",
    "\n",
    "На тестовой выборке алгоритм с оправдывающей себя регуляризацией показывает результат не хуже алгоритма без регуляризации. Добавление регуляризатора помогает бороться с переобучением, а значит, увеличивать обобщающую способность алгоритма. Алгоритм без регуляризации в свою очередь может иметь высокое качество на обучающей выборке, но ввиду сложности модели плохо работать на тестовой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.\n",
    "\n",
    "Accuracy score = $\\frac{Tr}{Tot}$, где $Tr$ - число верных ответов, $Tot$ - общее количество объектов \\\\\n",
    "\n",
    "Precision score = $\\frac{TP}{TP + FP}$, $TP$ - количество верных ответов класса 1, $FP$ - количество ложных ответов класса 1 (т.е. количество объектов класса 0, на которых алгоритм вернул 1)\n",
    "\n",
    "Recall score = $\\frac{TP}{TP + FN}$, $FN$ - количество ложных ответов класса 0 (объектов класса 1, на которых алгоритм вернул 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.\n",
    "\n",
    "Метрика качества AUC равна площади под ROC-кривой алгоритма \n",
    "\n",
    "ROC-кривая строится по следующему набору точек:\n",
    "\n",
    "Каждой точке соответствует порог принятия решения классификации (алгоритм возвращает вероятности, классификация бинарная). Для каждого порога вычисляются значения precision_score и recall_score, которые играют роль координат.\n",
    "Изменяя порог от 0 до 1, построим кривую по полученным точкам. Значению порога 1 соответствует precision=0, recall=1, значению 0 - precision=1, recall=1.\n",
    "\n",
    "Таким образом, кривая каким-то образом соединяет точки (0, 0) и (1, 1) и площадь под ней, соответственно, изменяется в пределах от 0 до 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.\n",
    "\n",
    "Приведем алгоритм построения ROC-кривой\n",
    "\n",
    "points = []\n",
    "for threshold in np.linspace(0, 1, 50):\n",
    "    points.append(get_point(clf, X, ans, threshold))\n",
    "\n",
    "def get_point(clf, X, ans, threshold):\n",
    "    predictions = []\n",
    "    for x in X:\n",
    "        pred = clf.predict_proba(x)\n",
    "        if pred > threshold:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "    \n",
    "    true_positive = np.sum(predictions[ans == 1])\n",
    "    false_positive = np.sum(predictions[ans == 0])\n",
    "    true_negative = len(predictions[ans == 0]) - \\ \n",
    "        np.sum(predictions[ans == 0])\n",
    "    false_negative = len(predictions[ans == 1]) - \\\n",
    "        np.sum(predictions[ans == 1])\n",
    "    \n",
    "    prec = true_positive / (true_positive + false_negative)\n",
    "    recall = true_negative / (true_negative + false_positive)\n",
    "    \n",
    "    return (prec, 1 - recall)\n",
    "\n",
    "Еще надо аккуратно обработать случаи нулевых значений, но это псведокод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Вероятностный смысл регуляризаторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим оптимизационную задачу минимизации функционала аппроксимированного эмпирического риска с регуляризацией:\n",
    "\n",
    "$Q = \\sum L(y_i, f(x_i)) + \\gamma V(w) \\rightarrow min$\n",
    "\n",
    "$\\sum -L(y_i, f(x_i)) - \\gamma V(w) \\rightarrow max$ \n",
    "\n",
    "$\\sum ln(e^{-L(y_i, f(x_i)}) + ln(e^{-\\gamma V(w)}) \\rightarrow max$\n",
    "\n",
    "$e^{-\\gamma V(w)} \\prod{e^{-L(y_i, f(x_i)}} \\rightarrow max$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, задачу нахождения оптимальных весов модели можно интерпретировать как задачу максимизации вероятности весов при условии объектов в байесовской модели.\n",
    "\n",
    "$P(w) \\sim e^{-\\gamma V(w)} \\prod {e^{-L(y_i, f(x_i)}} \\sim P(x_i, y_i | w)$\n",
    "\n",
    "L1 - регуляризации соответствует распределение Лапласа, а L2 - регуляризации - нормальное распределение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. SVM и максимизация разделяющей полосы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим линейный классификатор:\n",
    "\n",
    "$a(x) = sign(<w, x> - w_0)$\n",
    "\n",
    "Можно отнормировать веса модели так, что\n",
    "\n",
    "$min y_i (<w, x_i> - w_0) = 1$ (в случае линейно разделимых выборок)\n",
    "\n",
    "Тогда ширина разделяющей полосы может быть найдена как\n",
    "\n",
    "$<(x_{+} - x_{-}), \\frac{w}{\\| w \\|}>$\n",
    "\n",
    "$<(x_{+} - x_{-}), \\frac{w}{\\| w \\|}> = \n",
    "\\frac {<w, x_{+}> - <w, x_{-}>}{\\| w \\|} = \n",
    "\\frac {(w_0 + 1) - (w_0 - 1)}{\\| w \\|} = \n",
    "\\frac {2}{\\| w \\|}$ \n",
    "\n",
    "Поставим задачу максимизации разделяющей полосы:\n",
    "\n",
    "$<w, w> \\rightarrow min$\n",
    "\n",
    "$y_i(<w, x_i> - w_0) \\geq 1$\n",
    "\n",
    "Отсюда:\n",
    "\n",
    "$\\frac{1}{2} <w, w> + C \\sum \\xi_i \\rightarrow min$\n",
    "\n",
    "$y_i(<w, x_i> - w_0) \\geq 1 - \\xi_i$\n",
    "\n",
    "$\\xi_i \\geq 0$\n",
    "\n",
    "Перейдем к задаче безусловной оптимизации:\n",
    "\n",
    "Из 2 и 3 неравенств следует, что $\\xi$ можно представить в виде\n",
    "\n",
    "$\\xi = max\\{0, 1 - M_i\\} = (1 - M_i)_{+}$\n",
    "\n",
    "Тогда задча безусловной оптимизации будет выглядеть следующим образом:\n",
    "$\\sum (1 - M_i(w, w_0))_{+} + \\frac{1}{2C} \\|w\\|^2 \\rightarrow min$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Kernel trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достаточно перейти к полиноминальному ядру:\n",
    "\n",
    "$K(w, x) = (\\gamma <w, x> + r)^2$\n",
    "\n",
    "Это позволит строить в исходном пространстве объектов разделяющие поверхности степени 2\n",
    "\n",
    "Размерность спрямляющего пространства равна 5 $(x_1, x_2, x_1 x_2, x_1^2, x_2^2)$"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
